---
title: "Homework 3"
author: "Alexey Abramov"
date:  "10/6/2020"
output: github_document
---

# Setup
```{r, setup}
library(tidyverse)
library(patchwork)
library(hexbin)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(
  ggthemes::theme_clean() + theme(legend.position = "bottom")
  )

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.colour = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Load the dataset.

```{r}
library(p8105.datasets)
data("instacart")
instacart
```

### Problem 1

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns.  

How many aisles, and which are most items from?
Here we are using the count function and arranging from most to least.

```{r}
aisles_df = instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

There are `r nrow(aisles_df)` aisles in this dataset.  


Let's make a plot of these data.

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n)) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

Make a table with the three most popular items in these specific aisles: baking ingredients, dog food care, and packaged vegetable fruits.

First we'll get the aisles, count them, then rank them and put them in a table.   

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```

Apples versus ice cream.

If we want the average of a product at a certain time, we can use the group_by and then summarize functions.  

```{r}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour) %>% 
    knitr::kable()
```

# Problem 2

Read in data and data wrangling.  
Here we are pivoting to longer to create minute and activity columns, creating a weekday column that identifies weekday vs. weekend and then creating the day of the week into a factor variable with 7 levels.  

## Problem 2 Data Wrangling and EDA

```{r}
accel_df = read_csv("./data/accel_data.csv") %>%
  pivot_longer(activity.1:activity.1440, 
      names_to = "minute", 
      values_to = "activity_count",
      names_prefix = "activity.") %>% 
  mutate(
    weekdays = case_when(
      day %in% c("Monday","Tuesday","Wednesday","Thursday","Friday") ~  
        "weekday",
      day %in% c("Saturday","Sunday") ~ "weekend")) %>% 
  group_by(day, day_id) %>% 
  mutate(
    day = factor(day)) %>% 
  ungroup()
```

Summarizing data here and performing some calculations by the day of the week and performing a few group_by calculations to learn more about patterns in the dataset.

This is weekday vs. weekend
```{r}
accel_summary1 = 
  accel_df %>% 
  group_by(weekdays) %>% 
    summarize(
      mean_daily_activity = mean(activity_count, na.rm = TRUE)) %>% 
    knitr::kable()
accel_summary1
```

This is by day of the week.
```{r}
accel_summary2 = 
  accel_df %>% 
  group_by(day) %>% 
    summarize(
      mean_daily_activity = mean(activity_count, na.rm = TRUE)) %>% 
    knitr::kable()
accel_summary2
```

This is week to week.

```{r}
accel_summary3 = 
  accel_df %>% 
  group_by(week) %>% 
    summarize(
      mean_daily_activity = mean(activity_count, na.rm = TRUE)) %>% 
    knitr::kable()
accel_summary3
```

### Discussion

The activity count data has `r nrow(accel_df)` rows and `r ncol(accel_df)` columns.  The rows reflect activity count observed at every minute of the day.  Columns serve to group these data by week and day of the week. There is an additional column that groups the day of the week by weekday and weekend. 

The above summarized data show mean activity counts calculated by day of the week, weekday vs. weekend and also week to week. Provided these data, we can appreciate that this individual is more active and weekdays, less active and weekends.  More specifically, he is most active on Fridays and least active on Saturdays. Lastly, he was most active in the 2nd and 3rd week. 

## Problem 2 Plots

Recreating the summary table.
```{r}
accel_summary2b = 
  accel_df %>% 
  group_by(day) %>% 
    summarize(
      mean_daily_activity = mean(activity_count, na.rm = TRUE)) 
accel_summary2b
```

Hm.  This a plot of the daily averages across the week.  
```{r}
accel_plot1 = 
  accel_summary2b %>% 
  ggplot(aes(x = day, y = mean_daily_activity)) +
  geom_point()
```

```{r}
accel_plot2 = 
  accel_df %>% 
  ggplot(aes(x = minute, y = activity_count)) +
  geom_line() +
  ggtitle("Daily Activity Count") +
  xlab("Minute of the Day (min)") +
  ylab("Activity Count")
accel_plot2
```

Example to also consider, daily activity counts by day.  Here is the Friday activity count.  
```{r}
accel_plot3 = 
  accel_df %>% 
  filter(day == "Friday") %>% 
  ggplot(aes(x = minute, y = activity_count)) +
  geom_line() +
  ggtitle("Friday Activity Count") + 
  xlab("Minute of the Day (min)") +
  ylab("Activity Count")
accel_plot3
```

# Problem 3

## Problem 3 Data Wrangling and EDA

```{r}
library(p8105.datasets)
data("ny_noaa")

nyweather_df = ny_noaa %>% 
    separate(date, into = c("month", "day", "year"), sep = "-")
nyweather_df
```

Problem 2 Notes 
1.  Pivot longer, day, activity count in every minute of the day, and check minute of the day in numeric
2.  Add a variable for weekday and then weekend with mutate, and use factors so the day of the week is sensible.  
3.  Variable class
4.  Group_by week and then day, and summarize problem
5.  ggplot with geom_line

Problem 3 Notes
1.  Separate
2.  Count for most commonly observed, rank?
3.  Group_by and summarize, then filter
4.  Then ggplot
5.  Two panel with faceting
6. Two distinct plots with patchwork
7.  tmax and tmin is a scatterplot, but probably better with contour or hexplot
8.  filtering with ridgeplots

